
\section{Results and discussion}
\label{sec:results}
\subsection{RQ1: What source code properties characterize defective
    infrastructure as code scripts?}
After completing the \emph{Mann-Whitney U} test and \emph{Cliff's Delta} test
we can identify which properties have a $p-value < 0.05$ for all datasets (i.e.
Attribute, Command, Ensure, File, File mode, Hard coded string, Include, Lines
of code, Require and SSH Key). After analysis, we can see that we did not obtain exactly the same $p-values$ as the original paper, but we did get the same \emph{Cliff's Delta} values. For example, in our case, the \emph{Comment} property has a $p-value = 0.58$ for Mozilla whereas the original paper has a $p-value = 0.23$. Furthermore, we see that we obtain $p-values \eqsim 0.01$ for the \emph{URL} property, where the original paper obtains $p-value < 0.001$ for the Mirantis and Wikimedia organizations. We present these results in Table \ref{table:rq1-mirantis} for the Mirantis dataset, in Table \ref{table:rq1-mozilla} for the Mozilla dataset and in Table \ref{table:rq1-wikimedia} for the Wikimedia dataset.


\begin{table}[h]
    \caption{Validation of identified source code properties for Mirantis}
    \label{table:rq1-mirantis}
    \centering
    \begin{tabular}{|l|l|l|}
        \hline
        Property          & $p-value$ & $delta$ \\ \hline
        Attribute         & $<0.001$  & 0.47    \\ \hline
        Command           & 0.005     & 0.24    \\ \hline
        Comment           & $<0.001$  & 0.37    \\ \hline
        Ensure            & $<0.001$  & 0.38    \\ \hline
        File              & $<0.001$  & 0.36    \\ \hline
        File mode         & $<0.001$  & 0.41    \\ \hline
        Hard coded string & $<0.001$  & 0.55    \\ \hline
        Include           & $<0.001$  & 0.33    \\ \hline
        Lines of code     & $<0.001$  & 0.45    \\ \hline
        Require           & $<0.001$  & 0.36    \\ \hline
        SSH KEY           & $<0.001$  & 0.39    \\ \hline
        URL               & 0.009     & 0.22    \\ \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \caption{Validation of identified source code properties for Mozilla}
    \label{table:rq1-mozilla}
    \centering
    \begin{tabular}{|l|l|l|}
        \hline
        Property          & $p-value$ & $delta$ \\ \hline
        Attribute         & $<0.001$  & 0.40    \\ \hline
        Command           & $<0.001$  & 0.18    \\ \hline
        Comment           & 0.58      & 0.03    \\ \hline
        Ensure            & $<0.001$  & 0.09    \\ \hline
        File              & $<0.001$  & 0.18    \\ \hline
        File mode         & $<0.001$  & 0.24    \\ \hline
        Hard coded string & $<0.001$  & 0.40    \\ \hline
        Include           & $<0.001$  & 0.31    \\ \hline
        Lines of code     & $<0.001$  & 0.50    \\ \hline
        Require           & $<0.001$  & 0.19    \\ \hline
        SSH KEY           & $<0.001$  & 0.24    \\ \hline
        URL               & 0.081     & 0.08    \\ \hline
    \end{tabular}
\end{table}


\begin{table}[h]
    \caption{Validation of identified source code properties for Wikimedia}
    \label{table:rq1-wikimedia}
    \centering
    \begin{tabular}{|l|l|l|}
        \hline
        Property          & $p-value$ & $delta$ \\ \hline
        Attribute         & $<0.001$  & 0.47    \\ \hline
        Command           & 0.008     & 0.18    \\ \hline
        Comment           & $<0.001$  & 0.22    \\ \hline
        Ensure            & $<0.001$  & 0.29    \\ \hline
        File              & $<0.001$  & 0.31    \\ \hline
        File mode         & $<0.001$  & 0.24    \\ \hline
        Hard coded string & $<0.001$  & 0.55    \\ \hline
        Include           & $<0.001$  & 0.37    \\ \hline
        Lines of code     & $<0.001$  & 0.51    \\ \hline
        Require           & $<0.001$  & 0.32    \\ \hline
        SSH KEY           & $<0.001$  & 0.24    \\ \hline
        URL               & 0.011     & 0.17    \\ \hline
    \end{tabular}
\end{table}

\subsection{RQ3: How can we construct defect prediction models for
    infrastructure as code scripts using the identified source code properties?}
As mentionned in the previous section, we only used the principle components
that accounted for at least 95\% of the total variance. We can see in Table
\ref{table:pca} that only one or two principle components account for 95\% of
the total variance depending on the dataset. The number of principle components
for each dataset corresponds to the ones in the paper.\\

Since the paper doesn't specify the different parameters for the models,
it would be difficult to obtain exactly the same results. Nevertheless, we
obtained results that are very similar that bring to the same conclusions.
The results from the cross-validation for each model can be found in Table
\ref{table:mirantis-models} for the Mirantis dataset, in Table \ref{table:mozilla-models}
for the Mozilla dataset, in Table \ref{table:openstack-models} for the Openstack
dataset and in Table \ref{table:wikimedia-models} for the Wikimedia dataset.
We haven't included the results from the actual paper, since it's publicly
available.



\begin{table}[h]
    \caption{Cross-validation results for Mirantis}
    \label{table:mirantis-models}
    \centering
    \begin{tabular}{|l|l|l|l|l|l|}
        \hline
        ~          & RF       & NB       & LR       & KNN      & CART     \\ \hline
        AUC        & 0.701661 & 0.714252 & 0.750981 & 0.693334 & 0.659597 \\ \hline
        Recall     & 0.707425 & 0.407360 & 0.649691 & 0.672546 & 0.707425 \\ \hline
        Precision  & 0.701199 & 0.846909 & 0.798322 & 0.667389 & 0.701199 \\ \hline
        F1-measure & 0.695896 & 0.541781 & 0.708236 & 0.663964 & 0.698448 \\ \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \caption{Cross-validation results for Mozilla}
    \label{table:mozilla-models}
    \centering
    \begin{tabular}{|l|l|l|l|l|l|}
        \hline
        ~          & RF       & NB       & LR       & KNN      & CART     \\ \hline
        AUC        & 0.731664 & 0.699599 & 0.756323 & 0.713161 & 0.691230 \\ \hline
        Recall     & 0.649017 & 0.392519 & 0.565923 & 0.619417 & 0.627106 \\ \hline
        Precision  & 0.642651 & 0.831862 & 0.706600 & 0.604170 & 0.642550 \\ \hline
        F1-measure & 0.645764 & 0.532261 & 0.626990 & 0.608864 & 0.633393 \\ \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \caption{Cross-validation results for Openstack}
    \label{table:openstack-models}
    \centering
    \begin{tabular}{|l|l|l|l|l|l|}
        \hline
        ~          & RF       & NB       & LR       & KNN      & CART     \\ \hline
        AUC        & 0.647741 & 0.694343 & 0.659972 & 0.659195 & 0.574832 \\ \hline
        Recall     & 0.667616 & 0.368902 & 0.731321 & 0.687022 & 0.660176 \\ \hline
        Precision  & 0.653112 & 0.847009 & 0.643218 & 0.661449 & 0.655685 \\ \hline
        F1-measure & 0.660440 & 0.512676 & 0.682243 & 0.673287 & 0.657360 \\ \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \caption{Cross-validation results for Wikimedia}
    \label{table:wikimedia-models}
    \centering
    \begin{tabular}{|l|l|l|l|l|l|}
        \hline
        ~          & RF       & NB       & LR       & KNN      & CART     \\ \hline
        AUC        & 0.664721 & 0.709438 & 0.736270 & 0.699140 & 0.583164 \\ \hline
        Recall     & 0.591171 & 0.366128 & 0.586200 & 0.627349 & 0.587493 \\ \hline
        Precision  & 0.664007 & 0.885945 & 0.774041 & 0.732415 & 0.666620 \\ \hline
        F1-measure & 0.628276 & 0.515651 & 0.663515 & 0.673132 & 0.623400 \\ \hline
    \end{tabular}
\end{table}

\subsection{Repository Mining \& Issue Mining}
The result of our replication of the repository mining and XCM building is available in the repository under the \texttt{data/processed/<org>} folder. The \texttt{data} folder contains the following files:

\begin{itemize}
    \item \texttt{valid-repos.json} which the list of valid repositories for the organization
    \item \texttt{xcms folder} which contains the XCM for the organization
\end{itemize}

We would like to note that we were unable to fetch the full commit history for some OpenStack and Wikimedia repositories, as we did not have the processing power to fetch the lengthy commmit history for these repositories. We opted to only fetch the commits of the last two years if the full commit history was longer than 2000 commits. \\
For example, the OpenStack repository contains 252 000 commits, so we only fetch the commits from the past two years.


